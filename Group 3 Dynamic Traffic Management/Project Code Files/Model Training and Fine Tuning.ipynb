{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402479d6-82f7-4369-974b-5449ddcc87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written 68634 annotations across 18175 images to coco/annotations/instances_vehicles_only.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the paths\n",
    "input_json = \"coco/annotations/instances_train2017.json\"\n",
    "output_json = \"coco/annotations/instances_vehicles_only.json\"\n",
    "required_categories = ['car', 'motorcycle', 'bus', 'truck']\n",
    "\n",
    "# Load original COCO annotations\n",
    "with open(input_json, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Step 1: Filter categories\n",
    "category_ids = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "filtered_category_ids = [cat_id for cat_id, name in category_ids.items() if name in required_categories]\n",
    "\n",
    "# Step 2: Filter annotations\n",
    "filtered_annotations = [ann for ann in coco_data['annotations'] if ann['category_id'] in filtered_category_ids]\n",
    "image_ids = list({ann['image_id'] for ann in filtered_annotations})\n",
    "\n",
    "# Step 3: Filter images\n",
    "filtered_images = [img for img in coco_data['images'] if img['id'] in image_ids]\n",
    "\n",
    "# Step 4: Filter categories list\n",
    "filtered_categories = [cat for cat in coco_data['categories'] if cat['id'] in filtered_category_ids]\n",
    "\n",
    "# Step 5: Combine and save\n",
    "filtered_coco = {\n",
    "    'images': filtered_images,\n",
    "    'annotations': filtered_annotations,\n",
    "    'categories': filtered_categories\n",
    "}\n",
    "\n",
    "with open(output_json, 'w') as f:\n",
    "    json.dump(filtered_coco, f)\n",
    "\n",
    "print(f\"✅ Written {len(filtered_annotations)} annotations across {len(filtered_images)} images to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba36a23d-d143-4bbf-83ef-14dbcd6b82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train images: 100%|██████| 16357/16357 [01:11<00:00, 227.21it/s]\n",
      "Processing val images: 100%|██████████| 1818/1818 [00:07<00:00, 228.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted 16357 train images + 1818 val images to YOLO format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIGURATION: adjust paths if needed\n",
    "COCO_JSON   = Path(\"coco/annotations/instances_vehicles_only.json\")\n",
    "COCO_IMGDIR = Path(\"coco/train2017\")              \n",
    "OUT_DIR     = Path(\"yolodata\")                     # output root for YOLO data\n",
    "AUTO_DIR    = Path(\"path/to/your/Auto\")            \n",
    "SPLIT_RATIO = 0.1                                  # 10% of vehicle images → validation\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Make sure output folders exist\n",
    "for split in [\"train\", \"val\"]:\n",
    "    (OUT_DIR/ split/ \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (OUT_DIR/ split/ \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the filtered COCO JSON\n",
    "with open(COCO_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Build maps: image_id → (file_name, width, height)\n",
    "img_map = { img[\"id\"]: (img[\"file_name\"], img[\"width\"], img[\"height\"])\n",
    "            for img in data[\"images\"] }\n",
    "\n",
    "# Group annotations by image_id\n",
    "ann_by_img = {}\n",
    "for ann in data[\"annotations\"]:\n",
    "    ann_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# Create a list of all filtered image_ids\n",
    "all_img_ids = list(img_map.keys())\n",
    "\n",
    "# Split into train / val\n",
    "train_ids, val_ids = train_test_split(all_img_ids, test_size=SPLIT_RATIO, random_state=42)\n",
    "\n",
    "def process_set(img_ids, split):\n",
    "    \"\"\"\n",
    "    For each image_id in img_ids:\n",
    "      - copy the JPEG from COCO_IMGDIR → OUT_DIR/{split}/images/\n",
    "      - write a YOLO .txt file into OUT_DIR/{split}/labels/\n",
    "    \"\"\"\n",
    "    for img_id in tqdm(img_ids, desc=f\"Processing {split} images\"):\n",
    "        fn, w, h = img_map[img_id]\n",
    "        src_img = COCO_IMGDIR / fn\n",
    "        dst_img = OUT_DIR/ split/ \"images\"/ fn\n",
    "\n",
    "        # Copy the image\n",
    "        if not dst_img.exists():\n",
    "            shutil.copy(src_img, dst_img)\n",
    "\n",
    "        # Convert each annotation to YOLO format\n",
    "        anns = ann_by_img.get(img_id, [])\n",
    "        lines = []\n",
    "        for a in anns:\n",
    "            # Map category_id to a class index 0–3:\n",
    "            #  Suppose we assign:\n",
    "            #    0 = car\n",
    "            #    1 = motorcycle\n",
    "            #    2 = bus\n",
    "            #    3 = truck\n",
    "            cat_to_cls = {3: 0, 4: 1, 6: 2, 8: 3}\n",
    "            cls_idx = cat_to_cls[a[\"category_id\"]]\n",
    "\n",
    "            x, y, bw, bh = a[\"bbox\"]\n",
    "            xc = (x + bw/2) / w\n",
    "            yc = (y + bh/2) / h\n",
    "            nw = bw / w\n",
    "            nh = bh / h\n",
    "\n",
    "            lines.append(f\"{cls_idx} {xc:.6f} {yc:.6f} {nw:.6f} {nh:.6f}\")\n",
    "\n",
    "        # Write the .txt labels\n",
    "        lbl_name = fn.replace(\".jpg\", \".txt\")\n",
    "        with open(OUT_DIR/ split/ \"labels\"/ lbl_name, \"w\") as lf:\n",
    "            lf.write(\"\\n\".join(lines))\n",
    "\n",
    "# Process train split\n",
    "process_set(train_ids, \"train\")\n",
    "\n",
    "# Process val split\n",
    "process_set(val_ids, \"val\")\n",
    "\n",
    "print(f\"✅ Converted {len(train_ids)} train images + {len(val_ids)} val images to YOLO format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7a5858-91f6-4315-922d-6b77c9884974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged all autos into: yolodata\\train\\images\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG: point AUTO_DIR ───────────────────────\n",
    "AUTO_DIR = Path(\"D:\\Machine Learning\\Major Project\\Auto\")  \n",
    "YOLO_ROOT = Path(\"yolodata\")          # the root where train/ and val/ exist\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "img_dst = YOLO_ROOT / \"train\" / \"images\"\n",
    "lbl_dst = YOLO_ROOT / \"train\" / \"labels\"\n",
    "\n",
    "# Loop over each .txt in AUTO_DIR, rewrite its class to “4”, then copy .jpg/.txt\n",
    "for txt_path in AUTO_DIR.glob(\"*.txt\"):\n",
    "    # Read existing lines and replace the class index (first token) with “4”\n",
    "    new_lines = []\n",
    "    for line in txt_path.read_text().splitlines():\n",
    "        parts = line.split()\n",
    "        parts[0] = \"4\"  # set class index to 4 (next available after {0,1,2,3})\n",
    "        new_lines.append(\" \".join(parts))\n",
    "    # Write the modified label into the train/labels folder\n",
    "    (lbl_dst / txt_path.name).write_text(\"\\n\".join(new_lines))\n",
    "\n",
    "    # Copy the corresponding image (.jpg) into train/images\n",
    "    img_name = txt_path.with_suffix(\".jpg\").name\n",
    "    shutil.copy(AUTO_DIR / img_name, img_dst / img_name)\n",
    "\n",
    "print(\"✅ Merged all autos into:\", img_dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbe9628-54f2-44b5-8ff8-d7b4b0c99b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote data.yaml to yolodata\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "YOLO_ROOT = Path(\"yolodata\")\n",
    "data_yaml = f\"\"\"\\\n",
    "train: { (YOLO_ROOT / 'train' / 'images').resolve() }\n",
    "val:   { (YOLO_ROOT / 'val'   / 'images').resolve() }\n",
    "\n",
    "nc: 5\n",
    "names: ['car','motorcycle','bus','truck','auto']\n",
    "\"\"\"\n",
    "\n",
    "# Write to yolodata/data.yaml\n",
    "(Path(YOLO_ROOT) / \"data.yaml\").write_text(data_yaml)\n",
    "print(\"✅ Wrote data.yaml to\", YOLO_ROOT / \"data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9e7f41-9259-47c4-9fec-11a515b8a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in val set: {2: 595, 0: 4278, 1: 938, 3: 996}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "val_labels = Path(\"yolodata/val/labels\")\n",
    "class_counts = Counter()\n",
    "\n",
    "for txt_file in val_labels.glob(\"*.txt\"):\n",
    "    lines = txt_file.read_text().splitlines()\n",
    "    for line in lines:\n",
    "        cls = int(line.split()[0])\n",
    "        class_counts[cls] += 1\n",
    "\n",
    "print(\"Class counts in val set:\", dict(class_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714ee909-f57a-41af-bc89-198c56ec9335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 auto labels in train set.\n",
      "Only 0 autos available; moving all of them.\n",
      "✅ Moved 0 auto images + labels to val split.\n"
     ]
    }
   ],
   "source": [
    "import random, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────────────────────\n",
    "YOLO_ROOT    = Path(\"yolodata\")\n",
    "AUTO_CLASS   = 4            # class index for “auto”\n",
    "REQUESTED_MOVE = 40         # desired number of autos to move to val\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Paths to train/val images & labels\n",
    "train_images = YOLO_ROOT / \"train\" / \"images\"\n",
    "train_labels = YOLO_ROOT / \"train\" / \"labels\"\n",
    "val_images   = YOLO_ROOT / \"val\"   / \"images\"\n",
    "val_labels   = YOLO_ROOT / \"val\"   / \"labels\"\n",
    "\n",
    "# 1) Collect all train-label files whose first token == AUTO_CLASS\n",
    "auto_txts = []\n",
    "for txt in train_labels.glob(\"*.txt\"):\n",
    "    first_line = txt.read_text().splitlines()\n",
    "    if not first_line: \n",
    "        continue\n",
    "    first_token = first_line[0].split()[0]\n",
    "    if int(first_token) == AUTO_CLASS:\n",
    "        auto_txts.append(txt)\n",
    "\n",
    "total_autos = len(auto_txts)\n",
    "print(f\"Found {total_autos} auto labels in train set.\")\n",
    "\n",
    "move_count = min(REQUESTED_MOVE, total_autos)\n",
    "if move_count < REQUESTED_MOVE:\n",
    "    print(f\"Only {total_autos} autos available; moving all of them.\")\n",
    "\n",
    "random.seed(42)\n",
    "to_move = random.sample(auto_txts, move_count)\n",
    "\n",
    "for txt_path in to_move:\n",
    "    img_name = txt_path.with_suffix(\".jpg\").name\n",
    "    # Move label\n",
    "    shutil.move(txt_path, val_labels / txt_path.name)\n",
    "    # Move image\n",
    "    shutil.move(train_images / img_name, val_images / img_name)\n",
    "\n",
    "print(f\"✅ Moved {len(to_move)} auto images + labels to val split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a019130-7375-4b39-a849-3e9fbd7f865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in AUTO_DIR (first 10):\n",
      "  Datacluster Auto (1).jpg\n",
      "  Datacluster Auto (1).xml\n",
      "  Datacluster Auto (10).jpg\n",
      "  Datacluster Auto (10).xml\n",
      "  Datacluster Auto (100).jpg\n",
      "  Datacluster Auto (100).xml\n",
      "  Datacluster Auto (101).jpg\n",
      "  Datacluster Auto (101).xml\n",
      "  Datacluster Auto (102).jpg\n",
      "  Datacluster Auto (102).xml\n",
      "\n",
      "Sample .txt content: No .txt found\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "AUTO_DIR = Path(\"D:\\Machine Learning\\Major Project\\Auto\") \n",
    "print(\"Files in AUTO_DIR (first 10):\")\n",
    "for i, f in enumerate(sorted(AUTO_DIR.iterdir())):\n",
    "    if i >= 10: break\n",
    "    print(\" \", f.name)\n",
    "  \n",
    "# Also peek inside one .txt to see its class index\n",
    "some_txt = next(AUTO_DIR.glob(\"*.txt\"), None)\n",
    "print(\"\\nSample .txt content:\", some_txt.read_text().splitlines()[0] if some_txt else \"No .txt found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a09108-c5ad-4d11-afe2-db5c6fcbcbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 XML files to convert.\n",
      "✅ Conversion complete: XML → YOLO TXT and images copied to yolodata/train.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "AUTO_DIR = Path(\"D:\\Machine Learning\\Major Project\\Auto\")\n",
    "YOLO_TRAIN_IMAGES = Path(\"yolodata/train/images\")\n",
    "YOLO_TRAIN_LABELS = Path(\"yolodata/train/labels\")\n",
    "# Ensure these exist\n",
    "YOLO_TRAIN_IMAGES.mkdir(parents=True, exist_ok=True)\n",
    "YOLO_TRAIN_LABELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUTO_CLASS_IDX = 4\n",
    "\n",
    "xml_files = list(AUTO_DIR.glob(\"*.xml\"))\n",
    "print(f\"Found {len(xml_files)} XML files to convert.\")\n",
    "\n",
    "for xml_path in xml_files:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Read image filename & size from XML\n",
    "    img_filename = root.findtext(\"filename\")\n",
    "    size = root.find(\"size\")\n",
    "    width = float(size.findtext(\"width\"))\n",
    "    height = float(size.findtext(\"height\"))\n",
    "\n",
    "    # Collect YOLO lines\n",
    "    yolo_lines = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        cls_name = obj.findtext(\"name\")\n",
    "        if cls_name.lower() != \"auto\":\n",
    "            continue\n",
    "\n",
    "        bnd = obj.find(\"bndbox\")\n",
    "        xmin = float(bnd.findtext(\"xmin\"))\n",
    "        ymin = float(bnd.findtext(\"ymin\"))\n",
    "        xmax = float(bnd.findtext(\"xmax\"))\n",
    "        ymax = float(bnd.findtext(\"ymax\"))\n",
    "\n",
    "        # Convert to YOLO format (normalized center, width, height)\n",
    "        x_center = ((xmin + xmax) / 2) / width\n",
    "        y_center = ((ymin + ymax) / 2) / height\n",
    "        w_norm = (xmax - xmin) / width\n",
    "        h_norm = (ymax - ymin) / height\n",
    "\n",
    "        yolo_lines.append(f\"{AUTO_CLASS_IDX} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "    if not yolo_lines:\n",
    "        continue\n",
    "\n",
    "    # Write .txt in train/labels\n",
    "    txt_name = Path(img_filename).with_suffix(\".txt\")\n",
    "    (YOLO_TRAIN_LABELS / txt_name).write_text(\"\\n\".join(yolo_lines))\n",
    "\n",
    "    # Copy the .jpg into train/images\n",
    "    src_img = AUTO_DIR / img_filename\n",
    "    dst_img = YOLO_TRAIN_IMAGES / img_filename\n",
    "    if src_img.exists():\n",
    "        shutil.copy(src_img, dst_img)\n",
    "    else:\n",
    "        print(f\"⚠️ Image not found for {xml_path.name}: expected {img_filename}\")\n",
    "\n",
    "print(\"✅ Conversion complete: XML → YOLO TXT and images copied to yolodata/train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e1fd9d-8dde-412f-bbd9-b1a36069934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total auto TXT files created: 16509\n",
      "Label-class counts (should show only {4: some_number}): {0: 39589, 3: 8977, 1: 7787, 2: 5474, 4: 236}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "lbls = list((Path(\"yolodata/train/labels\")).glob(\"*.txt\"))\n",
    "print(f\"Total auto TXT files created: {len(lbls)}\")\n",
    "\n",
    "counts = Counter()\n",
    "for txt in lbls:\n",
    "    lines = txt.read_text().splitlines()\n",
    "    for ln in lines:\n",
    "        cls = int(ln.split()[0])\n",
    "        counts[cls] += 1\n",
    "\n",
    "print(\"Label-class counts (should show only {4: some_number}):\", dict(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ff6151-51de-4071-99ba-8696bc7db561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 40/152 autos to val\n",
      "✅ Moved selected autos to val.\n"
     ]
    }
   ],
   "source": [
    "import random, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "YOLO_ROOT     = Path(\"yolodata\")\n",
    "AUTO_CLASS    = 4\n",
    "REQUESTED_NUM = 40\n",
    "\n",
    "train_images = YOLO_ROOT / \"train\" / \"images\"\n",
    "train_labels = YOLO_ROOT / \"train\" / \"labels\"\n",
    "val_images   = YOLO_ROOT / \"val\"   / \"images\"\n",
    "val_labels   = YOLO_ROOT / \"val\"   / \"labels\"\n",
    "\n",
    "# Find auto label files\n",
    "auto_txts = []\n",
    "for txt in train_labels.glob(\"*.txt\"):\n",
    "    first = txt.read_text().splitlines()\n",
    "    if first and int(first[0].split()[0]) == AUTO_CLASS:\n",
    "        auto_txts.append(txt)\n",
    "\n",
    "move_n = min(REQUESTED_NUM, len(auto_txts))\n",
    "print(f\"Moving {move_n}/{len(auto_txts)} autos to val\")\n",
    "\n",
    "to_move = random.sample(auto_txts, move_n)\n",
    "for txt in to_move:\n",
    "    img = train_images / txt.with_suffix(\".jpg\").name\n",
    "    shutil.move(txt, val_labels / txt.name)\n",
    "    shutil.move(img, val_images / img.name)\n",
    "\n",
    "print(\"✅ Moved selected autos to val.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fb6b71-8d5e-44c1-afa1-0269082d2df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val‐set class counts: {2: 595, 0: 4278, 1: 938, 3: 996, 4: 60}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "val_lbls = list((Path(\"yolodata/val/labels\")).glob(\"*.txt\"))\n",
    "counts = Counter()\n",
    "for txt in val_lbls:\n",
    "    for ln in txt.read_text().splitlines():\n",
    "        cls = int(ln.split()[0])\n",
    "        counts[cls] += 1\n",
    "print(\"Val‐set class counts:\", dict(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376a7803-9eda-47ea-8b56-381e46253ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data.yaml updated: yolodata\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "YOLO_ROOT = Path(\"yolodata\")\n",
    "content = f\"\"\"\\\n",
    "train: { (YOLO_ROOT / 'train' / 'images').resolve() }\n",
    "val:   { (YOLO_ROOT / 'val'   / 'images').resolve() }\n",
    "\n",
    "nc: 5\n",
    "names: ['car','motorcycle','bus','truck','auto']\n",
    "\"\"\"\n",
    "\n",
    "(YOLO_ROOT / \"data.yaml\").write_text(content)\n",
    "print(\"✅ data.yaml updated:\", YOLO_ROOT / \"data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1708492-730c-402c-9577-06278e7374cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Auto-only: 95 in train, 17 in val\n"
     ]
    }
   ],
   "source": [
    "import random, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG ──────────────────────────────────────────────────────────────────────\n",
    "YOLO_ROOT   = Path(\"yolodata\")\n",
    "AUTO_CLASS  = 4            \n",
    "VAL_RATIO   = 0.15           # ~15% for validation\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "auto_train_imgs = YOLO_ROOT / \"train\" / \"images\"\n",
    "auto_train_lbls = YOLO_ROOT / \"train\" / \"labels\"\n",
    "\n",
    "# Create new folders\n",
    "AUTO_ROOT = YOLO_ROOT / \"auto\"\n",
    "for sub in [\"train/images\", \"train/labels\", \"val/images\", \"val/labels\"]:\n",
    "    (AUTO_ROOT / Path(sub)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Gather all “auto” label files from the main train split\n",
    "all_auto_txts = []\n",
    "for txt in auto_train_lbls.glob(\"*.txt\"):\n",
    "    first = txt.read_text().splitlines()\n",
    "    if first and int(first[0].split()[0]) == AUTO_CLASS:\n",
    "        all_auto_txts.append(txt)\n",
    "\n",
    "# Shuffle and split\n",
    "random.seed(42)\n",
    "random.shuffle(all_auto_txts)\n",
    "split_idx = int(len(all_auto_txts) * (1 - VAL_RATIO))\n",
    "train_auto = all_auto_txts[:split_idx]\n",
    "val_auto   = all_auto_txts[split_idx:]\n",
    "\n",
    "# Function to copy .jpg/.txt into target\n",
    "def copy_auto(txt_list, subset):\n",
    "    for txt in txt_list:\n",
    "        img_name = txt.with_suffix(\".jpg\").name\n",
    "        # Read original TXT content (already “4 x y w h”)\n",
    "        content = txt.read_text().splitlines()\n",
    "        # Rewrite class index to 0 for auto-only\n",
    "        new_lines = []\n",
    "        for line in content:\n",
    "            parts = line.split()\n",
    "            parts[0] = \"0\"\n",
    "            new_lines.append(\" \".join(parts))\n",
    "        # Write to auto/{subset}/labels\n",
    "        dest_lbl = AUTO_ROOT / subset / \"labels\" / txt.name\n",
    "        dest_lbl.write_text(\"\\n\".join(new_lines))\n",
    "        # Copy image to auto/{subset}/images\n",
    "        shutil.copy(auto_train_imgs / img_name, AUTO_ROOT / subset / \"images\" / img_name)\n",
    "\n",
    "# Copy training autos\n",
    "copy_auto(train_auto, \"train\")\n",
    "# Copy validation autos\n",
    "copy_auto(val_auto, \"val\")\n",
    "\n",
    "print(f\"✅ Auto-only: {len(train_auto)} in train, {len(val_auto)} in val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8501845-0e06-4932-99fa-feaec05e8f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto‐only train images: 95\n",
      "Auto‐only train labels: 95\n",
      "Auto‐only  val images: 17\n",
      "Auto‐only  val labels: 17\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "AUTO_ROOT = Path(\"yolodata/auto\")\n",
    "\n",
    "train_imgs = list((AUTO_ROOT/\"train\"/\"images\").glob(\"*.jpg\"))\n",
    "train_lbls = list((AUTO_ROOT/\"train\"/\"labels\").glob(\"*.txt\"))\n",
    "val_imgs   = list((AUTO_ROOT/\"val\"/\"images\").glob(\"*.jpg\"))\n",
    "val_lbls   = list((AUTO_ROOT/\"val\"/\"labels\").glob(\"*.txt\"))\n",
    "\n",
    "print(\"Auto‐only train images:\", len(train_imgs))\n",
    "print(\"Auto‐only train labels:\", len(train_lbls))\n",
    "print(\"Auto‐only  val images:\", len(val_imgs))\n",
    "print(\"Auto‐only  val labels:\", len(val_lbls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105739de-b9ea-4964-92b8-d7f134b73278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote auto_only.yaml to yolodata\\auto\\auto_only.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "AUTO_ROOT = Path(\"yolodata/auto\")\n",
    "content = f\"\"\"\\\n",
    "train: { (AUTO_ROOT / 'train' / 'images').resolve() }\n",
    "val:   { (AUTO_ROOT / 'val'   / 'images').resolve() }\n",
    "\n",
    "nc: 1\n",
    "names: ['auto']\n",
    "\"\"\"\n",
    "\n",
    "(AUTO_ROOT / \"auto_only.yaml\").write_text(content)\n",
    "print(\"✅ Wrote auto_only.yaml to\", AUTO_ROOT / \"auto_only.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028c95f1-c4a9-44eb-8521-af5f9acb31f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 original auto labels in train.\n",
      "✅ Duplicated each auto 3 times.\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Step 5: Oversample “auto” images in yolodata/train so they’re not underrepresented\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration: where your combined dataset lives\n",
    "YOLO_ROOT = Path(\"yolodata\")\n",
    "TRAIN_IMGS = YOLO_ROOT / \"train\" / \"images\"\n",
    "TRAIN_LBLS = YOLO_ROOT / \"train\" / \"labels\"\n",
    "AUTO_CLASS = 4  # class index for “auto”\n",
    "DUP_FACTOR = 3  # how many additional copies of each auto to make\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Find all “auto” label files in train/labels\n",
    "auto_txts = []\n",
    "for txt in TRAIN_LBLS.glob(\"*.txt\"):\n",
    "    first = txt.read_text().splitlines()\n",
    "    if first and int(first[0].split()[0]) == AUTO_CLASS:\n",
    "        auto_txts.append(txt)\n",
    "\n",
    "print(f\"Found {len(auto_txts)} original auto labels in train.\")\n",
    "\n",
    "# For each auto, create DUP_FACTOR copies with new names\n",
    "for txt_path in auto_txts:\n",
    "    base = txt_path.stem  \n",
    "    img_name = f\"{base}.jpg\"\n",
    "    src_img = TRAIN_IMGS / img_name\n",
    "\n",
    "    for i in range(DUP_FACTOR):\n",
    "        new_base = f\"{base}_dup{i}\"\n",
    "        # Copy image\n",
    "        dest_img = TRAIN_IMGS / f\"{new_base}.jpg\"\n",
    "        shutil.copy(src_img, dest_img)\n",
    "        # Copy label (same contents)\n",
    "        dest_lbl = TRAIN_LBLS / f\"{new_base}.txt\"\n",
    "        shutil.copy(txt_path, dest_lbl)\n",
    "\n",
    "print(f\"✅ Duplicated each auto {DUP_FACTOR} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5128461-15a9-4f21-a670-a78b9090017e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1125 auto .txt files to augment.\n"
     ]
    }
   ],
   "source": [
    "# Step: Augment “auto” images by flipping to balance class counts\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIGURATION\n",
    "YOLO_ROOT    = Path(\"yolodata\")\n",
    "TRAIN_IMAGES = YOLO_ROOT / \"train\" / \"images\"\n",
    "TRAIN_LABELS = YOLO_ROOT / \"train\" / \"labels\"\n",
    "AUTO_CLASS   = 4            # class index for “auto”\n",
    "AUG_DIR      = TRAIN_IMAGES # we’ll write augmented images/labels back into train folders\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def augment_autos():\n",
    "    # 1) Gather all original “auto” label files\n",
    "    auto_label_files = []\n",
    "    for txt in TRAIN_LABELS.glob(\"*.txt\"):\n",
    "        lines = txt.read_text().splitlines()\n",
    "        if not lines:\n",
    "            continue\n",
    "        cls = int(lines[0].split()[0])\n",
    "        if cls == AUTO_CLASS:\n",
    "            auto_label_files.append(txt)\n",
    "\n",
    "    print(f\"Found {len(auto_label_files)} auto .txt files to augment.\")\n",
    "\n",
    "    for txt_path in auto_label_files:\n",
    "        # Read the corresponding image\n",
    "        base_name = txt_path.stem\n",
    "        img_path = TRAIN_IMAGES / f\"{base_name}.jpg\"\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "\n",
    "        # Load image and label lines\n",
    "        img = Image.open(img_path)\n",
    "        w, h = img.size\n",
    "        label_lines = txt_path.read_text().splitlines()\n",
    "\n",
    "        # Perform 3 augmentations: horizontal flip, vertical flip, both\n",
    "        ops = [\n",
    "            (\"hflip\",   lambda im: im.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "            (\"vflip\",   lambda im: im.transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "            (\"hvflip\",  lambda im: im.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "        ]\n",
    "\n",
    "        for suffix, op in ops:\n",
    "            # 2) Create augmented image\n",
    "            aug_img = op(img)\n",
    "            new_basename = f\"{base_name}_{suffix}_{uuid.uuid4().hex[:8]}\"\n",
    "            new_img_path = AUG_DIR / f\"{new_basename}.jpg\"\n",
    "            aug_img.save(new_img_path)\n",
    "\n",
    "            # 3) Adjust and write label file\n",
    "            new_txt_path = TRAIN_LABELS / f\"{new_basename}.txt\"\n",
    "            new_lines = []\n",
    "            for line in label_lines:\n",
    "                parts = line.split()\n",
    "                cls_idx = parts[0]  # should be “4”\n",
    "                xc, yc, bw, bh = map(float, parts[1:5])\n",
    "\n",
    "                if suffix == \"hflip\":\n",
    "                    xc = 1.0 - xc\n",
    "                elif suffix == \"vflip\":\n",
    "                    yc = 1.0 - yc\n",
    "                elif suffix == \"hvflip\":\n",
    "                    xc = 1.0 - xc\n",
    "                    yc = 1.0 - yc\n",
    "\n",
    "                new_lines.append(f\"{cls_idx} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "            new_txt_path.write_text(\"\\n\".join(new_lines))\n",
    "\n",
    "    print(\"✅ Augmentation complete: horizontal, vertical, and both flips applied.\")\n",
    "\n",
    "\n",
    "# Run the augmentation\n",
    "augment_autos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a43121f-02b3-4b01-a376-10109b98ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 auto files needing augmentation.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "image file is truncated (43 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Finished augmenting those auto files.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Run the augmentation pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m augment_autos_once()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36maugment_autos_once\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m ops = [\n\u001b[32m     57\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_hflip_\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_LEFT_RIGHT)),\n\u001b[32m     58\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_vflip_\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_TOP_BOTTOM)),\n\u001b[32m     59\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_hvflip_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)),\n\u001b[32m     60\u001b[39m ]\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m suffix, op \u001b[38;5;129;01min\u001b[39;00m ops:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     aug_img = op(img)\n\u001b[32m     64\u001b[39m     new_basename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muuid.uuid4().hex[:\u001b[32m8\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     65\u001b[39m     new_img_path = TRAIN_IMAGES / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_basename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36maugment_autos_once.<locals>.<lambda>\u001b[39m\u001b[34m(im)\u001b[39m\n\u001b[32m     53\u001b[39m label_lines = txt_path.read_text().splitlines()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Define flip operations & suffixes\u001b[39;00m\n\u001b[32m     56\u001b[39m ops = [\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_hflip_\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_LEFT_RIGHT)),\n\u001b[32m     58\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_vflip_\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_TOP_BOTTOM)),\n\u001b[32m     59\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33m_hvflip_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m im: im.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)),\n\u001b[32m     60\u001b[39m ]\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m suffix, op \u001b[38;5;129;01min\u001b[39;00m ops:\n\u001b[32m     63\u001b[39m     aug_img = op(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\traffic-gpu\\Lib\\site-packages\\PIL\\Image.py:2989\u001b[39m, in \u001b[36mImage.transpose\u001b[39m\u001b[34m(self, method)\u001b[39m\n\u001b[32m   2978\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranspose\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: Transpose) -> Image:\n\u001b[32m   2979\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2980\u001b[39m \u001b[33;03m    Transpose image (flip or rotate in 90 degree steps)\u001b[39;00m\n\u001b[32m   2981\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2986\u001b[39m \u001b[33;03m    :returns: Returns a flipped or rotated copy of this image.\u001b[39;00m\n\u001b[32m   2987\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2989\u001b[39m     \u001b[38;5;28mself\u001b[39m.load()\n\u001b[32m   2990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28mself\u001b[39m.im.transpose(method))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\traffic-gpu\\Lib\\site-packages\\PIL\\ImageFile.py:297\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    293\u001b[39m         msg = (\n\u001b[32m    294\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mimage file is truncated \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes not processed)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    296\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m    300\u001b[39m n, err_code = decoder.decode(b)\n",
      "\u001b[31mOSError\u001b[39m: image file is truncated (43 bytes not processed)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# CONFIGURATION: paths and settings\n",
    "YOLO_ROOT    = Path(\"yolodata\")\n",
    "TRAIN_IMAGES = YOLO_ROOT / \"train\" / \"images\"\n",
    "TRAIN_LABELS = YOLO_ROOT / \"train\" / \"labels\"\n",
    "AUTO_CLASS   = 4  \n",
    "\n",
    "# Suffixes used by the previous augmentation that we want to skip\n",
    "SKIP_SUFFIXES = [\"_hflip_\", \"_vflip_\", \"_hvflip_\"]\n",
    "\n",
    "\n",
    "def needs_augmentation(txt_path):\n",
    "    \"\"\"\n",
    "    Return True if:\n",
    "    - The label’s first token is AUTO_CLASS (4), and\n",
    "    - The stem does not contain any of the SKIP_SUFFIXES.\n",
    "    \"\"\"\n",
    "    stem = txt_path.stem\n",
    "    for suffix in SKIP_SUFFIXES:\n",
    "        if suffix in stem:\n",
    "            return False\n",
    "\n",
    "    # Check the class index is AUTO_CLASS\n",
    "    lines = txt_path.read_text().splitlines()\n",
    "    if not lines:\n",
    "        return False\n",
    "    cls_idx = int(lines[0].split()[0])\n",
    "    return cls_idx == AUTO_CLASS\n",
    "\n",
    "def augment_autos_once():\n",
    "    # 1) Gather only those auto labels that still need augmentation\n",
    "    to_augment = [txt for txt in TRAIN_LABELS.glob(\"*.txt\") if needs_augmentation(txt)]\n",
    "    print(f\"Found {len(to_augment)} auto files needing augmentation.\")\n",
    "\n",
    "    for txt_path in to_augment:\n",
    "        # Load corresponding image\n",
    "        base_name = txt_path.stem\n",
    "        img_path = TRAIN_IMAGES / f\"{base_name}.jpg\"\n",
    "        if not img_path.exists():\n",
    "            continue  # skip if image missing\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        w, h = img.size\n",
    "\n",
    "        # Read the label lines (all start with \"4 x y w h\")\n",
    "        label_lines = txt_path.read_text().splitlines()\n",
    "\n",
    "        # Define flip operations & suffixes\n",
    "        ops = [\n",
    "            (\"_hflip_\",  lambda im: im.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "            (\"_vflip_\",  lambda im: im.transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "            (\"_hvflip_\", lambda im: im.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "        ]\n",
    "\n",
    "        for suffix, op in ops:\n",
    "            aug_img = op(img)\n",
    "            new_basename = f\"{base_name}{suffix}{uuid.uuid4().hex[:8]}\"\n",
    "            new_img_path = TRAIN_IMAGES / f\"{new_basename}.jpg\"\n",
    "            aug_img.save(new_img_path)\n",
    "\n",
    "            new_txt_path = TRAIN_LABELS / f\"{new_basename}.txt\"\n",
    "            new_lines = []\n",
    "            for line in label_lines:\n",
    "                parts = line.split()\n",
    "                # keep class 4\n",
    "                xc, yc, bw, bh = map(float, parts[1:5])\n",
    "\n",
    "                # adjust centers for flip\n",
    "                if suffix == \"_hflip_\":\n",
    "                    xc = 1.0 - xc\n",
    "                elif suffix == \"_vflip_\":\n",
    "                    yc = 1.0 - yc\n",
    "                elif suffix == \"_hvflip_\":\n",
    "                    xc = 1.0 - xc\n",
    "                    yc = 1.0 - yc\n",
    "\n",
    "                new_lines.append(f\"4 {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "            new_txt_path.write_text(\"\\n\".join(new_lines))\n",
    "\n",
    "    print(\"✅ Finished augmenting those auto files.\")\n",
    "\n",
    "\n",
    "# Run the augmentation pass\n",
    "augment_autos_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "172a2a13-e3ae-4563-b72f-ffc9a821ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post‐re‐augmentation train class counts: {0: 9975, 1: 2134, 3: 2324, 2: 1924, 4: 2111}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter()\n",
    "for txt in (TRAIN_LABELS).glob(\"*.txt\"):\n",
    "    cls = int(txt.read_text().split()[0])\n",
    "    counts[cls] += 1\n",
    "\n",
    "print(\"Post‐re‐augmentation train class counts:\", dict(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d0903-7a8e-4535-81fb-edb09b61189f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
